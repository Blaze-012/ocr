{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eaa99c22-a799-4b25-86c3-30ee80de77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f03f4bf6-2c28-4c5a-94e4-b9d5b6ff2c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"data/test_img.png\"\n",
    "image = \"data/test_img.png\"\n",
    "img = cv2.imread(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "29055fba-21c2-4d28-a3df-8f6240720f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2339, 1653, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "38d5099f-3999-44ea-8004-6b5072417817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/28816046/\n",
    "#displaying-different-images-with-actual-size-in-matplotlib-subplot\n",
    "def display(im_path):\n",
    "    dpi = 80\n",
    "    im_data = plt.imread(im_path)\n",
    "\n",
    "    height, width  = im_data.shape[:2]\n",
    "    \n",
    "    # What size does the figure need to be in inches to fit the image?\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "    # Create a figure of the right size with one axes that takes up the full figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "    # Hide spines, ticks, etc.\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Display the image.\n",
    "    ax.imshow(im_data, cmap='gray')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b9eb38fe-dae3-4256-a087-4a6a8fae4c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c5a33a3f-fc53-435f-8d31-2874afb7e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grayscale conversion\n",
    "def grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32ccabb1-98cd-4452-93c3-20b73908bffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_image = grayscale(img)\n",
    "cv2.imwrite(\"temp/gray.jpg\", gray_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18e680fe-d7b4-4463-ab98-d07d2389f455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2339, 1653)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f58511a-a762-4834-99cf-2dd8a073f846",
   "metadata": {},
   "source": [
    "## Binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6918faad-4504-4f43-a117-e9ca81d126a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh, im_bw = cv2.threshold(gray_image, 200,230, cv2.THRESH_BINARY)\n",
    "cv2.imwrite(\"temp/bw_image.jpg\",im_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab5b3c97-8166-495c-9697-88c1a590065e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.0\n"
     ]
    }
   ],
   "source": [
    "print(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4baa89f7-eabd-4103-81cd-3967ce389932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(\"temp/bw_image.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d33a2eb-25ec-4f07-a376-d66bcdc4401e",
   "metadata": {},
   "source": [
    "## Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9dceede-4853-4405-b28d-24647f895938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[   0,    0]],\n",
      "\n",
      "       [[   0, 2338]],\n",
      "\n",
      "       [[1652, 2338]],\n",
      "\n",
      "       [[1652,    0]]], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "cnts = cv2.findContours(im_bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cents[1]\n",
    "cnts = sorted(cnts, key=lambda x: cv2.boundingRect(x)[0])\n",
    "print(cnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "11ec3dfa-000d-4e4d-bb40-5e1f8a55d921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 1653, 2339)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Find contours\n",
    "contours, _ = cv2.findContours(im_bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Get bounding boxes around each contour\n",
    "bounding_boxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "print(bounding_boxes)\n",
    "# Draw bounding boxes\n",
    "for x, y, w, h in bounding_boxes:\n",
    "    img_bbox = cv2.rectangle(im_bw, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite(\"temp/bbox.png\",img_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec937b78-e4c7-45d1-bf61-ef0effb32d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for c in cnts:\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    # if h > 200 and w > 20:\n",
    "    roi = im_bw[y:y+h, x:x+h]\n",
    "    cv2.imwrite(\"temp/index_roi.png\", roi)\n",
    "    cv2.rectangle(im_bw, (x, y), (x+w, y+h), (36, 255, 12), 2)\n",
    "cv2.imwrite(\"temp/index_bbox_new.png\", im_bw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f35bb1-bcf5-4dd2-9d71-f32b99171119",
   "metadata": {},
   "source": [
    "## Italics detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5449b408-d84c-4969-8e87-5d884f985537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa3b4429-d7de-4eab-bd67-a3d07e80c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/67577793/detecting-bold-and-italic-text-in-an-image\n",
    "KERNEL = np.asarray([\n",
    "    [1, 1, 1, 1],\n",
    "    [1, 1, 1, 1],\n",
    "    [1, 1, 1, 1],\n",
    "], np.uint8)\n",
    "KERNEL_ITALIC = np.asarray([\n",
    "    [0, 0, 1, 1],\n",
    "    [0, 0, 1, 1],\n",
    "    [0, 0, 1, 1],\n",
    "    [0, 1, 1, 0],\n",
    "    [0, 1, 1, 0],\n",
    "    [0, 1, 1, 0],\n",
    "    [1, 1, 0, 0],\n",
    "    [1, 1, 0, 0],\n",
    "    [1, 1, 0, 0],\n",
    "], np.uint8)\n",
    "\n",
    "def pre_process_italic(img):\n",
    "    img_f = cv2.flip(img, 1)\n",
    "\n",
    "    img = cv2.erode(img, KERNEL_ITALIC, iterations=1)\n",
    "    img = cv2.dilate(img, KERNEL, iterations=1)\n",
    "\n",
    "    img_f = cv2.erode(img_f, KERNEL_ITALIC, iterations=1)\n",
    "    img_f = cv2.dilate(img_f, KERNEL, iterations=1)\n",
    "    img_f = cv2.flip(img_f, 1)\n",
    "    return img, img_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b1c437f-2187-4cc7-99e8-4845b548f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_func_italic(bbox, original, preprocessed):\n",
    "\n",
    "    b_1 = bbox[1]\n",
    "    b_3 = bbox[3]\n",
    "    b_0 = bbox[0]\n",
    "    b_2 = bbox[2]\n",
    "\n",
    "    a, b = np.mean(original[b_1:b_3, b_0:b_2]), np.mean(preprocessed[b_1:b_3, b_0:b_2])\n",
    "\n",
    "    return get_ratio(a, b)\n",
    "\n",
    "def get_ratio(a, b):\n",
    "    return ((a - b) / (a + b + 1e-8)) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f7076047-7f2c-40d6-a845-ca48b3a68ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, img_f = pre_process_italic(im_bw)\n",
    "ratio_1 = apply_func_italic(cnts, im_bw, img)\n",
    "ratio_2 = apply_func_italic(cnts, im_bw, img_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21814036-c4cd-41da-b3af-f17029796334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
